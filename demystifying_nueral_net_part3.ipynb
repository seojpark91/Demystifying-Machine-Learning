{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demystifying Neural Network \n",
    "\n",
    "## Pytorch tutorial\n",
    "- What is pytorch?\n",
    "- Why everyone talks about GPUs in neural network?\n",
    "- All about tensors\n",
    "    - What is a tensor?\n",
    "    - Tensor's rank, axes, and shape\n",
    "        - Shape of a tensor \n",
    "    - 4 ways to create Pytorch tensor objects\n",
    "    - Memory Sharing - different pytorch object constructors\n",
    "    - Converting numpy arrays into pytorch tensor object\n",
    "    - different tensor data types\n",
    "- Tensor Manipulation: Flatten, Reshape, and Squeeze\n",
    "- Broadcasting operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "I started taking a course on *Natural Language Processing with Pytorch* last week at FastCampus. So, in this notebook, I am going to practice tensor manipulation with pytorch. Although pytorch is very similar to numpy, I am still not 100% familiar with all tensor manipulation concepts and codes (reshape, concatenate, broadcasting, etc). This notebook will cover only basics, but I am going to add more Pytorch tutorial practice notebook as the course goes on. Most of the information I wrote in this notebook is from Deeplizard and the course material that I mentioned above. Check out [Deeplizard](http://deeplizard.com/) website since they have awesome pytorch tutorial for beginners! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is pytorch?\n",
    "Pytorch is an open-source deep learning neural network package for Python. Pytorch tensor objects (primary data structure used by neural networks) are created from Numpy `ndarray` objects. Thus, Pytorch and Numpy share basic operations. We can build a nueral network with Numpy, but problems are that computations cannot run on GPUs (Graphic Processing Units) and we have to compute our gradients. This might be ok if we only have only few layers, but it will be absolutely impossible to do so when we have to build deep neural networks. On the other hand, we can easily build neural networks via deep learning frameworks (in our case, Pytorch!) and compute gradients. It can also run computations efficiently on GPUs. Therefore, Pytorch is targeted at the audience who (1) wants to use the power of GPUs to build and train neural network and (2) needs a deep learning platform that offers flexibility and speed. \n",
    "\n",
    "### Why everyone talks about GPUs in neural network programming? \n",
    "Frankly, I did not know what a GPU is until I took a course on deep learning. So, I want to explain briefly about a GPU that everyone talks about in neural network programming. \n",
    "\n",
    "We all have CPUs (Central Processing Units) since a CPU is the processor that power most of the typical computations on our electronic devices. Although a CPU has fewer cores, each core is much faster and good at multi-tasking (sequential tasks). On the other hand, a GPU is more cores (sometimes has almost 1000 times more cores than a CPU!), but each core is much slower. However, it has its advanages; it is really good at one thing: parallel computing.\n",
    "\n",
    "Then, what is parallel computing? Parallel computing is a type of computation in which a big computation is broken into small independent computations. Matrix multiplication is a great example of parallel computing, the main operation within neural network. You see, in matrix multiplication, each computation is independent. When we do matrix multiplication, we multiply each column of B by each row of A. \n",
    "\n",
    "<img src=\"img/blog3_figure1.png\" width=400, height=200>\n",
    "\n",
    "If we break really big computations into smaller independent computations and feed to a GPU, it can handle the computations very quickly by utilizing its numerous cores simultaneously. That's great, right? then why don't we just do every computation in GPU? Well, a GPU can be much faster at computing than a CPU, but we have to be careful since it is costly to move data from a CPU to a GPU. If we send every computation (even a simple computation that does not need the power of GPUs), overall performance might be slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All about tensors\n",
    "\n",
    "### What is a tensor?\n",
    "As I mentioned above, tensor is the primary data structure used in neural networks. I first thought that the term tensor is some kind of a new data type that I have to learn all over again, BUT it was not! The concept of a tensor is a \"mathematical generalization of other more specific concepts.\" Basically, it's a generalized concept of a vector. \n",
    "\n",
    "The field of computer science and that of mathematics call the same concepts differently:  \n",
    "(Computer Science, Mathematics) --> (number, scalar), (array, vector), (2d-array, matrix)  \n",
    "2 terms inside each tuple mean the same thing, but the same concept is called differently in two fields. Tensor is a term that solves this confusion. Thus, instead of calling nd-array for CS folks or nd-matrix for mathematicians, we can just have nd-tensor that can generalize concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor's rank, axes, and shape\n",
    "For me, one of the most confusing concepts was the shape of a tensor. By reading materials on Deeplizard, I realized that a tensor's rank, axes, and shape are all fundamentally connected with a tensor's indices. If I understand how they are connected.\n",
    "- rank of a tensor: the number of dimensions present within a tensor\n",
    "- axes of a tensor: specific dimension of a tensor. Rank-4 tensor means it has 4 dimensions (4 axes)\n",
    "- shape of a tensor: shape of a tensor is determined by the length of each axis\n",
    "\n",
    "Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "(3, 3)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# we have a rank-1 tensor since it requires 1 index to get a component of d_1_tensor \n",
    "d_1_tensor = np.array([1,1,1,1,1])\n",
    "print(d_1_tensor[0])\n",
    "\n",
    "# here, we have a rank-2 tensor since it requires 2 inices to get a component of d_2_tensor\n",
    "d_2_tensor = np.array([[1,1,1],\n",
    "                       [2,2,2],\n",
    "                       [3,3,3]])\n",
    "\n",
    "print(d_2_tensor[1][0]) \n",
    "\n",
    "\n",
    "print(d_2_tensor.shape) # d_2_tensor has a shape of (3,3)\n",
    "print(len(d_2_tensor.shape)) # the length of the shape is 2 showing its rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shape of a tensor\n",
    "\n",
    "<img src=\"img/blog3_figure2.png\" width=400, height=200>\n",
    "Above shows typical tensor shapes for two scenarios: computer vision, natural language processing.\n",
    "For example, for computer vision, B represents batch size: how many samples are in a batch. Then, we pick a color channel, choose a hieght, then we choose a width to arrive at a specific pixel value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 5,  7,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[1,2,3],\n",
    "                 [4,5,6]],\n",
    "                 [[5,7,9],\n",
    "                 [10,11,12]]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) torch.Size([2, 2, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x.size(), x.shape) # size and shape give us the same value\n",
    "print(len(x.shape)) # length of a tensor's shape is equal to the rank of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 ways to create Pytorch tensor objects\n",
    "\n",
    "There are 4 ways to get tensor objects via Pytorch:  \n",
    "1) `torch.Tensor(data)`  \n",
    "2) `torch.tensor(data)`  \n",
    "3) `torch.as_tensor(data)`  \n",
    "4) `torch.from_numpy(data)`  \n",
    "\n",
    "I made 1d-array with numpy below and converted to a tensor object via above 4 methods. First, the `torch.Tensor` constructor gives us the default tensor data type. Therefore, even though we made the data with integers, when we construct a tensor object with `torch.Tensor` constructor, we get the data type `torch.float32`. On the other hand, other constructor types `torch.tensor`, `torch.as_tensor`, and `torch.from_numpy` give us the same data type. It turns out that the methods 2,3 and 4 are factory functions. Factory function is a function that accepts parameter inputs and returns particular type of object. This allows more dynamic object creation. Thus, methods 2,3, and 4 do type inference when we make tensor with those methods. Otherwise, we can also assign a data type to a tensor when creating one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([2., 3., 4.]) torch.float32\n",
      "tensor([2, 3, 4]) torch.int64\n",
      "tensor([2, 3, 4]) torch.int64\n",
      "tensor([2, 3, 4]) torch.int64\n",
      "tensor([ 0.2000,  0.4500, -0.0014], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([2, 3, 4])\n",
    "print(torch.get_default_dtype()) # pytorch default data type is float32\n",
    "t1 = torch.Tensor(data)\n",
    "t2 = torch.tensor(data)\n",
    "t3 = torch.as_tensor(data)\n",
    "t4 = torch.from_numpy(data)\n",
    "\n",
    "print(t1, t1.dtype)\n",
    "print(t2, t2.dtype)\n",
    "print(t3, t3.dtype)\n",
    "print(t4, t4.dtype)\n",
    "\n",
    "# if we pass input data as a numpy array, tensor constructor infers its data type from the input\n",
    "print(torch.tensor(np.array([0.2, 0.45, -0.0014]))) \n",
    "\n",
    "torch.tensor([2, 3, 4], dtype = torch.float64) # we can also assign a data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Sharing - different pytorch object constructors\n",
    "It gets interesting when we change values of the data without redefining above tensor objects. I'm going to change the values of the array as below and print out each created tensor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0] = 0\n",
    "data[1] = 1\n",
    "data[2] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see the difference below? `t1`and `t2` are constructed with `torch.Tensor` and `torch.tensor`, respectively, and `t3`and `t4` are with `torch.as_tensor` and `torch.from_numpy`, respectively. Changing the data did not affect `t1` and `t2`, while it did for `t3` and `t4`. This difference comes from how memory is allocated within each of above creation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4.])\n",
      "tensor([2, 3, 4])\n",
      "tensor([0, 1, 2])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while `torch.Tensor` and `torch.tensor` **copy** the input numpy array, `torch.as_tensor` and `torch.from_numpy` **share** memory with the input array. This means that we can move between numpy and pytorch seamlessly. Using `torch.as_tensor` and `torch.from_numpy` constructors can be very fast when creating a tensor object since pytorch object constructed with these methods share memory with an input numpy array. Therefore, any changes made within numpy data will be reflected on a pytorch object that are made with `torch.as_tensor` and `torch.from_numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting numpy arrays into pytorch tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1]) <class 'torch.Tensor'>\n",
      "[1 1 1 1 1] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "d_1_tensor = torch.from_numpy(d_1_tensor)\n",
    "print(d_1_tensor, type(d_1_tensor))\n",
    "\n",
    "# pytorch tensor object can also be converted to numpy array\n",
    "d_1_tensor = d_1_tensor.numpy()\n",
    "print(d_1_tensor, type(d_1_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -2.5244e-29,  6.0774e+10],\n",
       "        [-8.5920e+09,  4.2039e-45,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(3,3) # making a random (3,3) tensor with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "ft # elements of the input is integer, but FloatTensor changes integer values into float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 23],\n",
      "        [31, 46]])\n",
      "tensor([[4, 0, 0],\n",
      "        [0, 1, 3]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([[12, 23],\n",
    "                      [31, 46]])\n",
    "print(lt) # long tensor has 64-bit integer values\n",
    "\n",
    "bt = torch.ByteTensor([[4, 0, 0],\n",
    "                       [0, 1, 3]])\n",
    "print(bt) # ByteTensor has 8-bit integer values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- changing tensor's data type using: `x.long()`, `x.float()`, `x.byte()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[12., 23.],\n",
      "        [31., 46.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(ft.long())\n",
    "print(lt.float())\n",
    "print(ft.byte())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Manipulation: Flatten, Reshape, and Squeeze\n",
    "#### reshaping operation  \n",
    "- With Pytorch, we can reshape a tensor with `x.view(n,m)`and `x.reshape(n,m)`\n",
    "- we can also change rank with `squeeze`, `unsqueeze`, `flatten`\n",
    "`squeeze` removes all of the dimensions or axes that have a length of 1  \n",
    "`unsqueeze`adds a dimension with a length of 1  \n",
    "`flatten` removes all of the axes except for 1. This creates another tensor with a single axis which contains the elements of a tensor. Thus, when we flatten a tensor, we create a 1d-tensor of the given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  5,  7,  9, 10, 11, 12]),\n",
       " tensor([ 1,  2,  3,  4,  5,  6,  5,  7,  9, 10, 11, 12]),\n",
       " 12)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because the tensor x contains 12 elements, \n",
    "x.view(12), x.view(-1), x.numel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[[1,1,1],\n",
    "                  [2,2,2],\n",
    "                  [3,3,3]]])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a flatten function using reshape and squeeze\n",
    "def flatten(t):\n",
    "    t = t.reshape(1,-1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 2, 2, 2, 3, 3, 3]), tensor([1, 1, 1, 2, 2, 2, 3, 3, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(y), y.flatten() # both give the same 1d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(1,-1) # reshape function only \"reshapes\" only while flatten does reshaping and squezzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1) # however, if we put -1, it gives us the same result as flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's say there are 4 images represented by t1, t2, t3, t4 vectors. Let's say these 4 images will make a one batch of an input of CNN. We know that we have to flatten this batch in order to feed in to the network. How can we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1]])\n",
    "\n",
    "t2 = torch.tensor([[2,2,2,2],\n",
    "                  [2,2,2,2],\n",
    "                  [2,2,2,2],\n",
    "                  [2,2,2,2]])\n",
    "t3 = torch.tensor([[3,3,3,3],\n",
    "                  [3,3,3,3],\n",
    "                  [3,3,3,3],\n",
    "                  [3,3,3,3]])\n",
    "\n",
    "t4 = torch.tensor([[4,4,4,4],\n",
    "                  [4,4,4,4],\n",
    "                  [4,4,4,4],\n",
    "                  [4,4,4,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]),\n",
       " torch.Size([4, 4]),\n",
       " torch.Size([4, 4]),\n",
       " torch.Size([4, 4]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape, t2.shape, t3.shape, t4.shape # we have 4 x 4 (H x W) 2d-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2]],\n",
       "\n",
       "        [[3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3]],\n",
       "\n",
       "        [[4, 4, 4, 4],\n",
       "         [4, 4, 4, 4],\n",
       "         [4, 4, 4, 4],\n",
       "         [4, 4, 4, 4]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.stack((t1,t2,t3,t4)) # Let's stack all 4 images so that we have 1 batch made of 4 images\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 4, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we have only 3 rank. \n",
    "# As we saw, a typical setting for an image tesor has 4 ranks - (# of images, # of color channels, height, width)\n",
    "# Thus, we put color channel axis to the index 1 (for simplicity, let's say that we have only 1 color channel)\n",
    "t = t.unsqueeze(1) # we 'unsqueeze' at axis 1 so that a color channel is included in our tensor\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0] # we can access the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0][0] # first color channel in the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0][0][0] # the first row of pixels in the first color channel of the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- However if we just do `t.reshape(-1)`, we cannot get individual prediction for each image since `t.reshape(-1)` will ignore separations among images and just make a single 1d-tensor. In order to prevent that we can use parameter `start_dim` of `flatten`function. by adding `start_dim = 1` argument, we can see that batch size is preserved and it flattens only color channel, height and width of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by \n",
    "t.flatten(start_dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten(start_dim = 1).shape # batch size is preserved! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### broadcasting operation\n",
    "- you probably also have seen the concept of broadcasting when you learned numpy. Broadcasting refers to element-wise tensor operation. Therefore, same shape is required to do broadcasting operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3],\n",
       "        [3, 3, 3, 3],\n",
       "        [3, 3, 3, 3],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + 2 # you see, when we add 2 to t1 2 is added to each element of t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see this with `np.broadcast_to` function, we convert a value 2 to match the shape of t1. This is precisely what's going on under the hood when we do `t1 + 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2],\n",
       "       [2, 2, 2, 2],\n",
       "       [2, 2, 2, 2],\n",
       "       [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(2, t1.shape) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
